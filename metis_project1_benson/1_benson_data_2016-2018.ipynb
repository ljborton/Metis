{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Default behavior grabs the most recent weeks. ISO format YYYY-MM-DD'''\n",
    "def mta_url_list(weeks, start=None):\n",
    "    base_url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\" #180630\n",
    "    td = timedelta(days=7)\n",
    "    func = lambda x: x\n",
    "    if start:\n",
    "        start = [int(x) for x in start.split(\"-\")]\n",
    "        start_date = date(start[0], start[1], start[2])\n",
    "        func = lambda x: start_date + td*x\n",
    "    else:\n",
    "        latest_date = date(2018, 6, 30)\n",
    "        func = lambda x: latest_date - td*x\n",
    "    return [str.format(base_url, func(i).strftime(\"%y%m%d\")) for i in list(range(weeks))]\n",
    "\n",
    "def read_csv(url):\n",
    "    print(\"Reading\", url)\n",
    "    return pd.read_csv(\n",
    "        StringIO(requests.get(url).content.decode('utf8'))\n",
    "    )\n",
    "\n",
    "'''We're interested in the spring (March-May, about 14 weeks) of years 2016, 2017, and 2018.'''\n",
    "l_2016 = mta_url_list(13, \"2016-03-05\")\n",
    "l_2017 = mta_url_list(14, \"2017-03-04\")\n",
    "l_2018 = mta_url_list(14, \"2018-03-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column names for easier use\n",
    "def column_name_cleanup(df):\n",
    "    # Rename C/A to make it neater\n",
    "    df.rename(columns={\"C/A\":\"CA\"}, inplace=True)\n",
    "    # Strip whitespace\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(columns=['DESC', 'UNIT', 'DIVISION'])\n",
    "    # Drop NaN rows\n",
    "    df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate by year, otherwise data is too big to handle well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160305.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160312.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160319.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160326.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160402.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160409.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160416.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160423.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160430.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160507.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160514.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160521.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_160528.txt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df16 = pd.concat([read_csv(url) for url in l_2016],ignore_index=True)\n",
    "df16 = column_name_cleanup(df16)\n",
    "df16.to_csv('rawdata2016.csv')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170304.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170311.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170318.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170325.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170401.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170408.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170415.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170422.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170429.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170506.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170513.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170520.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170527.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_170603.txt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df17 = pd.concat([read_csv(url) for url in l_2017],ignore_index=True)\n",
    "df17 = column_name_cleanup(df17)\n",
    "df17.to_csv('rawdata2017.csv')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180303.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180310.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180317.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180324.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180331.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180407.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180414.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180421.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180428.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180505.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180512.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180519.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180526.txt\n",
      "Reading http://web.mta.info/developers/data/nyct/turnstile/turnstile_180602.txt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df18 = pd.concat([read_csv(url) for url in l_2018],ignore_index=True)\n",
    "df18 = column_name_cleanup(df18)\n",
    "df18.to_csv('rawdata2018.csv')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part makes a really big file, you probably don't want that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_total = pd.concat([df16, df17, df18])\n",
    "df_total.to_csv('rawdata_all.csv')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

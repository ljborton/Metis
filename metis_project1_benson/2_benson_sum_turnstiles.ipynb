{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df16 = pd.read_csv('rawdata2016.csv')\n",
    "df17 = pd.read_csv('rawdata2017.csv')\n",
    "df18 = pd.read_csv('rawdata2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/27/2016</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>5562172</td>\n",
       "      <td>1877574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/27/2016</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>5562184</td>\n",
       "      <td>1877586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/27/2016</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>5562267</td>\n",
       "      <td>1877691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/27/2016</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>5562516</td>\n",
       "      <td>1877745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/27/2016</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>5562920</td>\n",
       "      <td>1877821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/27/2016</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>5563175</td>\n",
       "      <td>1877862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>5563262</td>\n",
       "      <td>1877882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>5563273</td>\n",
       "      <td>1877892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>5563346</td>\n",
       "      <td>1877954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>5563545</td>\n",
       "      <td>1878026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>5563838</td>\n",
       "      <td>1878078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>5564010</td>\n",
       "      <td>1878116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/29/2016</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>5564033</td>\n",
       "      <td>1878126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/29/2016</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>5564051</td>\n",
       "      <td>1878164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A002</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>02/29/2016</td>\n",
       "      <td>10:26:51</td>\n",
       "      <td>5564205</td>\n",
       "      <td>1878502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA       SCP STATION LINENAME        DATE      TIME  ENTRIES    EXITS\n",
       "0   A002  02-00-00   59 ST   NQR456  02/27/2016  03:00:00  5562172  1877574\n",
       "1   A002  02-00-00   59 ST   NQR456  02/27/2016  07:00:00  5562184  1877586\n",
       "2   A002  02-00-00   59 ST   NQR456  02/27/2016  11:00:00  5562267  1877691\n",
       "3   A002  02-00-00   59 ST   NQR456  02/27/2016  15:00:00  5562516  1877745\n",
       "4   A002  02-00-00   59 ST   NQR456  02/27/2016  19:00:00  5562920  1877821\n",
       "5   A002  02-00-00   59 ST   NQR456  02/27/2016  23:00:00  5563175  1877862\n",
       "6   A002  02-00-00   59 ST   NQR456  02/28/2016  03:00:00  5563262  1877882\n",
       "7   A002  02-00-00   59 ST   NQR456  02/28/2016  07:00:00  5563273  1877892\n",
       "8   A002  02-00-00   59 ST   NQR456  02/28/2016  11:00:00  5563346  1877954\n",
       "9   A002  02-00-00   59 ST   NQR456  02/28/2016  15:00:00  5563545  1878026\n",
       "10  A002  02-00-00   59 ST   NQR456  02/28/2016  19:00:00  5563838  1878078\n",
       "11  A002  02-00-00   59 ST   NQR456  02/28/2016  23:00:00  5564010  1878116\n",
       "12  A002  02-00-00   59 ST   NQR456  02/29/2016  03:00:00  5564033  1878126\n",
       "13  A002  02-00-00   59 ST   NQR456  02/29/2016  07:00:00  5564051  1878164\n",
       "14  A002  02-00-00   59 ST   NQR456  02/29/2016  10:26:51  5564205  1878502"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine data for each year\n",
    "df = pd.concat([df16, df17, df18])\n",
    "# What is \"Unnamed: 0\"?\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations = ['34 ST-PENN STA']\n",
    "stations = ['CANAL ST', '33 ST', '23 ST', '14 ST', '28 ST', '34 ST-PENN STA']\n",
    "\n",
    "def calc_delta(d):\n",
    "    d['NEXT LINE TURNSTILE'] = d['SCP'].shift(-1)\n",
    "    d['DELTA_ENTRY'] = np.where(d['NEXT LINE TURNSTILE'] == d['SCP'], d['ENTRIES'].shift(-1) - d['ENTRIES'], 0)\n",
    "    d['DELTA_EXIT'] = np.where(d['NEXT LINE TURNSTILE'] == d['SCP'], d['EXITS'].shift(-1) - d['EXITS'], 0)\n",
    "    d['TOTAL_DELTA'] = d['DELTA_ENTRY'] + d['DELTA_EXIT']\n",
    "    len_before = len(d)\n",
    "    d = d[(d['TOTAL_DELTA'] < 10000) &(d['TOTAL_DELTA']> 0)]\n",
    "    len_after = len(d)\n",
    "    len_lost = len_before - len_after\n",
    "    print(\"{0:.0%}\".format(len_lost/len_before), \"rows unusable\")\n",
    "    return d\n",
    "\n",
    "def calc_datetime(d):\n",
    "    d[\"datetime_str\"] = d.DATE + \" \" + d.TIME\n",
    "    d[\"datetime\"] = pd.to_datetime(d[\"datetime_str\"], infer_datetime_format=True)\n",
    "    d.drop(columns=[\"datetime_str\"], inplace=True)\n",
    "    d['day_of_week'] = d['datetime'].dt.weekday_name\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing CANAL ST\n",
      "11% rows unusable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/jessica/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/jessica/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/jessica/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7110511102646261 wkdy vs. 0.28894888973537386 wknd\n",
      "\n",
      "Processing 33 ST\n",
      "12% rows unusable\n",
      "0.7135527618590417 wkdy vs. 0.28644723814095835 wknd\n",
      "\n",
      "Processing 23 ST\n",
      "17% rows unusable\n",
      "0.7216614296936371 wkdy vs. 0.27833857030636294 wknd\n",
      "\n",
      "Processing 14 ST\n",
      "7% rows unusable\n",
      "0.7108544428402678 wkdy vs. 0.2891455571597322 wknd\n",
      "\n",
      "Processing 28 ST\n",
      "13% rows unusable\n",
      "0.7259851000807827 wkdy vs. 0.2740148999192173 wknd\n",
      "\n",
      "Processing 34 ST-PENN STA\n",
      "10% rows unusable\n",
      "0.7188272377687474 wkdy vs. 0.2811727622312527 wknd\n"
     ]
    }
   ],
   "source": [
    "# Make dict of dataframes for each station\n",
    "frames = {}\n",
    "for station in stations:\n",
    "    print()\n",
    "    print(\"Processing\", station)\n",
    "    d = df[df['STATION'] == station]\n",
    "    d = calc_delta(d)  # Add DELTA columns for entry and exit\n",
    "    d = calc_datetime(d)  # Combine date and time as datetime object\n",
    "    d = d.dropna()\n",
    "    # Separate weekend and weekday data\n",
    "    d_wknd = d[(d['day_of_week'] == 'Saturday') | (d['day_of_week'] == 'Sunday')]\n",
    "    frames[station+\" wknd\"] = d_wknd\n",
    "    d_wkdy = d[(d['day_of_week'] != 'Saturday') & (d['day_of_week'] != 'Sunday')]\n",
    "    frames[station+\" wkdy\"] = d_wkdy\n",
    "    # Show ratio of weekday to weekend data\n",
    "    print(len(d_wkdy)/len(d), \"wkdy vs.\", len(d_wknd)/len(d), \"wknd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    CANAL ST 0.7167051960035321 wkdy vs. 0.2832948039964679 wknd\n",
    "    33 ST 0.7158699708301579 wkdy vs. 0.28413002916984204 wknd\n",
    "    23 ST 0.7165942189150029 wkdy vs. 0.2834057810849972 wknd\n",
    "    14 ST 0.715475514453368 wkdy vs. 0.28452448554663207 wknd\n",
    "    28 ST 0.7164351671015421 wkdy vs. 0.2835648328984579 wknd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each station, about 72% of the data was collected on a weekday and 28% was collected on weekends. We're graphing them separately because traffic might be drastically different due to the typical work/school schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find total traffic for each entrance of station (sum of SCP).\n",
    "def groupby_sum(station):\n",
    "    return station.groupby(by=['CA', 'STATION', 'DATE', 'TIME']).sum()\n",
    "\n",
    "# Average hourly traffic for each entrance of station.\n",
    "def groupby_mean(station):\n",
    "    return station.groupby(by=['CA', 'STATION', 'TIME']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed CANAL_ST_wknd.csv\n",
      "Completed CANAL_ST_wkdy.csv\n",
      "Completed 33_ST_wknd.csv\n",
      "Completed 33_ST_wkdy.csv\n",
      "Completed 23_ST_wknd.csv\n",
      "Completed 23_ST_wkdy.csv\n",
      "Completed 14_ST_wknd.csv\n",
      "Completed 14_ST_wkdy.csv\n",
      "Completed 28_ST_wknd.csv\n",
      "Completed 28_ST_wkdy.csv\n",
      "Completed 34_ST-PENN_STA_wknd.csv\n",
      "Completed 34_ST-PENN_STA_wkdy.csv\n"
     ]
    }
   ],
   "source": [
    "for key, station in frames.items():\n",
    "    station = groupby_sum(station)\n",
    "    station = groupby_mean(station)\n",
    "    station.sort_values(by=['TIME'], inplace=True)\n",
    "    fn = key.replace(\" \", \"_\") + \".csv\"\n",
    "    station.to_csv(fn)\n",
    "    print(\"Completed\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
